---
layout: about
title: about
permalink: /
subtitle: <b>PhD student at EPFL ðŸ‡¨ðŸ‡­ advised by <a href="https://people.epfl.ch/nicolas.flammarion">Nicolas Flammarion</a></b>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: Enjoying the gorgeous ðŸ‡¨ðŸ‡­ peaks! This one is <a href="https://en.wikipedia.org/wiki/Rochers_de_Naye">Rochers de Naye</a>. #>
    # <p>EPFL, Lausanne, ðŸ‡¨ðŸ‡­</p>
    

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

**Short bio.** I'm a fourth-year PhD student in computer science at EPFL ðŸ‡¨ðŸ‡­. Previously, I did my MSc at Saarland University and the University of TÃ¼bingen and interned at Adobe Research. My research mainly focuses on developing a better understanding of the training dynamics of deep networks and their adversarial robustness. My research is supported by the Google and OpenPhil PhD Fellowships.

<!-- **Formal bio.** Maksym Andriushchenko is a fourth-year PhD student in computer science at EPFL (Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne) in Switzerland. He obtained his MSc from Saarland University, Germany. His research mainly focuses on how to better understand the training dynamics of deep networks and make machine learning algorithms adversarially robust. Maksym has published eleven papers at major machine learning and computer vision conferences (NeurIPS, ICML, ICLR, CVPR, ECCV, etc). His research is supported by the Google and OpenPhil PhD Fellowships. -->


**Research interests.**
I'm interested in understanding why machine learning works and why it fails. I believe that understanding the training dynamics of gradient descent methods (especially, with [large step sizes](https://openreview.net/forum?id=ipRGZ91NvG4), procedures like [sharpness-aware minimization](https://arxiv.org/abs/2206.06232) and in [fine-tuning large language models](https://arxiv.org/abs/2006.04884)) is key to understand generalization in deep learning. I also keep my interest in adversarial robustness ([formal guarantees](https://arxiv.org/abs/1705.08475), [Square Attack](https://arxiv.org/abs/1912.00049), [fast adversarial training](https://arxiv.org/abs/2007.02617), [RobustBench](https://arxiv.org/abs/2010.09670)) and out-of-distribution generalization ([curious ReLU properties](https://arxiv.org/abs/1812.05720), [robustness on corruptions](https://arxiv.org/abs/2103.02325)). 



**On Ukraine.** Since I'm from Ukraine, I'm often asked about the situation in my country and how one can help. The most effective way is to donate to *local Ukrainian organization helping on the ground*, e.g., see [this list](https://fundforukraine.ml/) which includes both trusted military and humanitarian organizations. You can also host displaced scholars and students from Ukraine, e.g., see the [#ScienceForUkraine project](https://scienceforukraine.eu/) where I'm involved as a volunteer. Also, you can also help by simply spreading the word about the war and going to demonstrations in your city. It's very important that we don't normalize [annexations of territories](https://en.wikipedia.org/wiki/2022_annexation_referendums_in_Russian-occupied_Ukraine), [numerous war crimes](https://en.wikipedia.org/wiki/War_crimes_in_the_2022_Russian_invasion_of_Ukraine), [mass deportations](https://theconversation.com/ukraine-war-reports-of-mass-deportations-recall-russias-dark-history-of-forcible-relocations-190272), and [nuclear threats](https://www.theatlantic.com/newsletters/archive/2022/09/russias-nuclear-threats/671571/). Otherwise, we'll end up in a world we don't really want to be in.
