---
layout: post
date: 2024-04-02 
inline: true
---


**Our new paper [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151) is available online (see a [Twitter/X thread](https://twitter.com/maksym_andr/status/1775877106422951938) for a summary). We show how to jailbreak basically *all* leading safety-aligned LLMs with â‰ˆ100% success rate.**
