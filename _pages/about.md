---
layout: about
title: about
permalink: /
# subtitle: <b>PhD student at EPFL ðŸ‡¨ðŸ‡­ 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: Enjoying the gorgeous ðŸ‡¨ðŸ‡­ peaks! This one is <a href="https://en.wikipedia.org/wiki/Rochers_de_Naye">Rochers de Naye</a>. #>
    # <p>EPFL, Lausanne, ðŸ‡¨ðŸ‡­</p>
    

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

**[[email](mailto:maksym@andriushchenko.me)]** &emsp; &nbsp;
**[[twitter](https://twitter.com/maksym_andr)]** &emsp; &nbsp;
**[[google scholar](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ)]** &emsp; &nbsp;
**[[github](https://github.com/max-andr)]** &emsp; &nbsp;
**[[cv](assets/pdf/CV, Maksym Andriushchenko, Sep 2022.pdf)]**

<!-- github_username: max-andr # your GitHub user name
# gitlab_username: # your GitLab user name
twitter_username: maksym_andr # your Twitter handle
linkedin_username: maksym-andriushchenko # your LinkedIn user name
scholar_userid: ZNtuJYoAAAAJ -->

**Short bio.** I'm a fourth-year PhD student in computer science at EPFL ðŸ‡¨ðŸ‡­ advised by [Nicolas Flammarion](https://people.epfl.ch/nicolas.flammarion). I did my MSc at Saarland University and the University of TÃ¼bingen, and interned at Adobe Research. 
<!-- My current research mainly focuses on developing a better understanding of the training dynamics of deep networks and their adversarial robustness.  -->
My research is supported by the Google and OpenPhil PhD Fellowships.

<!-- **Formal bio.** Maksym Andriushchenko is a fourth-year PhD student in computer science at EPFL (Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne) in Switzerland. He obtained his MSc from Saarland University, Germany. His research mainly focuses on how to better understand the training dynamics of deep networks and make machine learning algorithms adversarially robust. Maksym has published eleven papers at major machine learning and computer vision conferences (NeurIPS, ICML, ICLR, CVPR, ECCV, etc). His research is supported by the Google and OpenPhil PhD Fellowships. -->


**Research interests.**
I'm interested in understanding why machine learning works and why it fails. I believe that understanding the training dynamics of gradient methods (especially, of SGD [with large step sizes](https://arxiv.org/abs/2210.05337), procedures like [sharpness-aware minimization](https://arxiv.org/abs/2206.06232), and [fine-tuning language models](https://arxiv.org/abs/2006.04884)) is key to understand generalization in deep learning. I also keep my interest in adversarial robustness ([formal guarantees](https://arxiv.org/abs/1705.08475), [square attack](https://arxiv.org/abs/1912.00049), [fast adversarial training](https://arxiv.org/abs/2007.02617), [RobustBench](https://arxiv.org/abs/2010.09670)) and out-of-distribution generalization ([curious ReLU properties](https://arxiv.org/abs/1812.05720), [robustness on corruptions](https://arxiv.org/abs/2103.02325)). 



**On Ukraine.** Since I'm from Ukraine, I'm often asked about the situation in my country and how one can help. The most effective way is to donate to *local Ukrainian organization helping on the ground*, e.g., see [this list](https://fundforukraine.ml/) which includes both trusted military and humanitarian organizations. You can also host displaced scholars and students from Ukraine, e.g., see the [#ScienceForUkraine project](https://scienceforukraine.eu/) where I'm involved as a volunteer. You can also help by simply spreading the word about the war and going to demonstrations in your city. It's very important that we don't normalize [annexations of territories](https://en.wikipedia.org/wiki/2022_annexation_referendums_in_Russian-occupied_Ukraine), [numerous war crimes](https://en.wikipedia.org/wiki/War_crimes_in_the_2022_Russian_invasion_of_Ukraine), [mass deportations](https://theconversation.com/ukraine-war-reports-of-mass-deportations-recall-russias-dark-history-of-forcible-relocations-190272), and [nuclear threats](https://www.theatlantic.com/newsletters/archive/2022/09/russias-nuclear-threats/671571/). Otherwise, we'll end up in a world we don't really want to be in.


<!-- ## highlight -->

<!-- Check our ICML'22 paper -->
<!-- ![sam](./assets/img/publication_preview/sam_paper.png) -->
<!-- <div style="text-align: center;">
  <img src="./assets/img/publication_preview/sam_paper.png" alt="SAM slide" width="75%"/>
</div> -->



<!-- ## selected publications
Full list: **[google scholar](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ)**

**M. Andriushchenko**, N. Flammarion. *[Towards Understanding Sharpness-Aware Minimization](https://arxiv.org/abs/2206.06232)* (ICML'22)

**M. Andriushchenko**, X. Li, G. Oxholm, T. Gittings, T. Bui, N. Flammarion, J. Collomosse *[ARIA: Adversarially Robust Image Attribution](https://arxiv.org/abs/2202.12860)* (CVPR'22 Workshop on Media Forensics)

F. Croce\*, **M. Andriushchenko\***, V. Sehwag*, N. Flammarion, M. Chiang, P. Mittal, M. Hein. RobustBench: a standardized adversarial robustness benchmark (NeurIPS'21 Datasets and Benchmarks Track, Best Paper Honorable Mention Prize at ICLR'21 Workshop on Security and Safety in Machine Learning Systems)

M. Mosbach, **M. Andriushchenko**, D. Klakow. On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines (ICLR'21)

**M. Andriushchenko**, N. Flammarion. Understanding and Improving Fast Adversarial training (NeurIPS'20) 

**M. Andriushchenko\***, F. Croce\*, N. Flammarion, M. Hein. Square Attack: a query-efficient black-box adversarial attack via random search (ECCV'20)

**M. Andriushchenko**, M. Hein. Provably Robust Boosted Decision Stumps and Trees against Adversarial Attacks
(NeurIPS'19)

M. Hein, **M. Andriushchenko**, J. Bitterwolf. Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem (oral at CVPR'19, 5.6% acceptance rate)

M. Hein and **M. Andriushchenko**. Formal Guarantees on the Robustness of a Classifier Against Adversarial Manipulation (NeurIPS'17) -->