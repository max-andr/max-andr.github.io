---
layout: post
date: 2024-12-22 
inline: true
---


Our paper [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151) has been featured on [EPFL's main webpage](https://actu.epfl.ch/news/can-we-convince-ai-to-answer-harmful-requests/), in [Blick](https://www.blick.ch/digital/epfl-forscher-knacken-sicherheitssperren-von-chatgpt-co-bomben-bauen-drogen-mischen-server-hacken-id20417778.html) (the largest newspaper in Switzerland), and other media [[1](https://techxplore.com/news/2024-12-convince-ai.html), [2](https://www.techexplorist.com/recent-large-language-models-remain-vulnerable-simple-manipulations/94951/), [3](https://www.miragenews.com/can-we-convince-ai-to-answer-harmful-requests-1382469/)].

