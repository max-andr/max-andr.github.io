---
layout: about
# title: about
permalink: /
# subtitle: <b>PhD student at EPFL ðŸ‡¨ðŸ‡­ 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: Enjoying the gorgeous ðŸ‡¨ðŸ‡­ peaks! This one is <a href="https://en.wikipedia.org/wiki/Rochers_de_Naye">Rochers de Naye</a>. #>
    # <p>EPFL, Lausanne, ðŸ‡¨ðŸ‡­</p>
    

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---


**[`Email`](mailto:maksym@andriushchenko.me)** &emsp; 
**[`Twitter/X`](https://twitter.com/maksym_andr)** &emsp; 
**[`Google Scholar`](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ)** &emsp; 
**[`GitHub`](https://github.com/max-andr)** &emsp; 
**[`CV`](assets/pdf/cv.pdf)**

<!-- github_username: max-andr # your GitHub user name
# gitlab_username: # your GitLab user name
twitter_username: maksym_andr # your Twitter handle
linkedin_username: maksym-andriushchenko # your LinkedIn user name
scholar_userid: ZNtuJYoAAAAJ -->

**Short bio.** I'm a fifth-year PhD student in computer science at EPFL ðŸ‡¨ðŸ‡­ advised by [Nicolas Flammarion](https://people.epfl.ch/nicolas.flammarion). My research is supported by the [Google](https://research.google/outreach/phd-fellowship/recipients/) and [Open Phil AI](https://www.openphilanthropy.org/grants/open-phil-ai-fellowship-2022-class/) PhD Fellowships. I did my MSc at Saarland University and the University of TÃ¼bingen, and interned at Adobe Research. 
<!-- My current research mainly focuses on developing a better understanding of the training dynamics of deep networks and their adversarial robustness.  -->
<!-- **Formal bio.** Maksym Andriushchenko is a fourth-year PhD student in computer science at EPFL (Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne) in Switzerland. He obtained his MSc from Saarland University, Germany. His research mainly focuses on how to better understand the training dynamics of deep networks and make machine learning algorithms adversarially robust. Maksym has published eleven papers at major machine learning and computer vision conferences (NeurIPS, ICML, ICLR, CVPR, ECCV, etc). His research is supported by the Google and OpenPhil PhD Fellowships. -->


**Research interests.**
<!-- My primary research goal is to understand generalization in deep learning. I'm interested in the training dynamics of commonly used algorithms (e.g., [SGD with large step sizes](https://arxiv.org/abs/2210.05337), [sharpness-aware minimization](https://arxiv.org/abs/2206.06232), [fine-tuning language models](https://arxiv.org/abs/2006.04884)), adversarial robustness ([formal guarantees](https://arxiv.org/abs/1705.08475), [square attack](https://arxiv.org/abs/1912.00049), [fast adversarial training](https://arxiv.org/abs/2007.02617), [RobustBench](https://arxiv.org/abs/2010.09670)), and out-of-distribution generalization ([curious ReLU properties](https://arxiv.org/abs/1812.05720), generalization to image [corruptions](https://arxiv.org/abs/2103.02325) and [digital manipulations](https://arxiv.org/abs/2202.12860)).  -->
<!-- My primary research goal is to *understand generalization in deep learning*. Towards this goal, I've worked on adversarial robustness, out-of-distribution generalization, implicit regularization, and sharpness-aware minimization. These days, I'm looking more into optimization and generalization properties of language models. My full publication list is available [here](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ). -->
My primary research goal is to understand robustness and generalization in deep learning. Toward this goal, Iâ€™ve worked on adversarial robustness, out-of-distribution generalization, implicit regularization, and sharpness-aware minimization. These days, Iâ€™m focusing almost entirely on various aspects of large language models, such as optimization, alignment, memorization, and robustness. My complete publication list is available [here](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ).


**On Ukraine.** Since I'm from Ukraine, I'm often asked about the situation in my country and how one can help. The most effective way is to donate to *local Ukrainian organization helping on the ground*, e.g., see [this list](https://standforukraine.com/) which includes both trusted military and humanitarian organizations. You can also host displaced scholars and students from Ukraine, e.g., see the [#ScienceForUkraine project](https://scienceforukraine.eu/) where I'm involved as a volunteer. You can also help simply by spreading the word about the war and going to demonstrations in your city. It's very important that we don't normalize [annexations of territories](https://en.wikipedia.org/wiki/2022_annexation_referendums_in_Russian-occupied_Ukraine), [numerous war crimes](https://en.wikipedia.org/wiki/War_crimes_in_the_2022_Russian_invasion_of_Ukraine), [mass deportations](https://theconversation.com/ukraine-war-reports-of-mass-deportations-recall-russias-dark-history-of-forcible-relocations-190272), and [nuclear threats](https://www.theatlantic.com/newsletters/archive/2022/09/russias-nuclear-threats/671571/). Otherwise, we'll end up in a world we don't really want to be in.


<!-- ## highlight -->

<!-- Check our ICML'22 paper -->
<!-- ![sam](./assets/img/publication_preview/sam_paper.png) -->
<!-- <div style="text-align: center;">
  <img src="./assets/img/publication_preview/sam_paper.png" alt="SAM slide" width="75%"/>
</div> -->



<!-- ## selected publications
Full list: **[google scholar](https://scholar.google.com/citations?user=ZNtuJYoAAAAJ)**

**M. Andriushchenko**, N. Flammarion. *[Towards Understanding Sharpness-Aware Minimization](https://arxiv.org/abs/2206.06232)* (ICML'22)

**M. Andriushchenko**, X. Li, G. Oxholm, T. Gittings, T. Bui, N. Flammarion, J. Collomosse *[ARIA: Adversarially Robust Image Attribution](https://arxiv.org/abs/2202.12860)* (CVPR'22 Workshop on Media Forensics)

F. Croce\*, **M. Andriushchenko\***, V. Sehwag*, N. Flammarion, M. Chiang, P. Mittal, M. Hein. RobustBench: a standardized adversarial robustness benchmark (NeurIPS'21 Datasets and Benchmarks Track, Best Paper Honorable Mention Prize at ICLR'21 Workshop on Security and Safety in Machine Learning Systems)

M. Mosbach, **M. Andriushchenko**, D. Klakow. On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines (ICLR'21)

**M. Andriushchenko**, N. Flammarion. Understanding and Improving Fast Adversarial training (NeurIPS'20) 

**M. Andriushchenko\***, F. Croce\*, N. Flammarion, M. Hein. Square Attack: a query-efficient black-box adversarial attack via random search (ECCV'20)

**M. Andriushchenko**, M. Hein. Provably Robust Boosted Decision Stumps and Trees against Adversarial Attacks
(NeurIPS'19)

M. Hein, **M. Andriushchenko**, J. Bitterwolf. Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem (oral at CVPR'19, 5.6% acceptance rate)

M. Hein and **M. Andriushchenko**. Formal Guarantees on the Robustness of a Classifier Against Adversarial Manipulation (NeurIPS'17) -->