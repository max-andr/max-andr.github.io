---
layout: post
date: 2024-05-31
inline: true
---


Our new paper [Is In-Context Learning Sufficient for Instruction Following in LLMs?](https://arxiv.org/abs/2405.19874) is available online (see a [Twitter/X thread](https://twitter.com/maksym_andr/status/1796574290797604892) for a summary).
We study alignment of *base* models, including GPT-4-Base (!), via many-shot in-context learning. I.e., no fine-tuning whatsoever, just prompting - *how far can we go?* Check the paper for more details.
<!-- Many people are thinking these days whether in-context learning with long-context LLMs can substitute fine-tuning altogether. Is it really true? Our paper provides a clear answer: no. -->